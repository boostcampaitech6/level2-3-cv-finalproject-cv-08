'''
author: Bai Yeqi
email: yeqi.bai@yitu-inc.com
'''
'''
Reload the generator checkpoint, inference with provided audio, in form of .wav
    or .m4a

We infer with different policies:
    1. Generate the face conditioned on each segment
    2. Generate the face conditioned on the whole speech
    3. Generate the face with the fuser
'''


import os
import shutil
import glob
import pyprind
import glog as log
import torch
import numpy as np
from imageio import imwrite

import models
from utils.wav2mel import wav_to_mel
from datasets import imagenet_deprocess_batch, set_mel_transform, \
    deprocess_and_save, window_segment
from options.opts import args, options


torch.backends.cudnn.benchmark = True


def main():
    global args, options
    print(args)
    device = torch.device('cuda')
    float_dtype = torch.cuda.FloatTensor
    long_dtype = torch.cuda.LongTensor

    image_normalize_method = options["data"]["data_opts"].get(
        'image_normalize_method', 'imagenet')
    print('image_normalize_method:', image_normalize_method)
    mel_normalize_method = options["data"]["data_opts"].get(
        'mel_normalize_method', 'vox_mel')
    mel_transform = set_mel_transform(mel_normalize_method)

    # Model
    log.info("Building Generative Model...")
    print(options["generator"])
    model, _ = models.build_model(
            options["generator"],
            image_size=options["data"]["image_size"],
            checkpoint_start_from=args.checkpoint_start_from)
    model.cuda().eval()
    
    # voice_path = os.path.join(args.input_wav_dir, '*.wav')
    # voice_list = glob.glob(voice_path)
    # filename = voice_list[0]
    filename = os.path.join(args.input_wav_file)
    assert os.path.exists(filename), "File not found: {}".format(filename)

    # for filename in voice_list:
    # result_sub_dir = filename.replace('.wav', '')
    # os.makedirs(result_sub_dir, exist_ok=True) # 결과 폴더 생성
    # Load mel_spectrogram
    log_mel = wav_to_mel(filename)
    log_mel = mel_transform(log_mel).type(float_dtype)
    #print(log_mel)
    log_mel_segs = window_segment(
        log_mel, window_length=125, stride_length=63)
    log_mel = log_mel.unsqueeze(0)

    # image generated by fuser
    # if args.fuser_infer:
    with torch.no_grad():
        imgs_fused, others = model(log_mel_segs.unsqueeze(0))
    if isinstance(imgs_fused, tuple):
        imgs_fused = imgs_fused[-1]
    imgs_fused = imgs_fused.cpu().detach()
    imgs_fused = imagenet_deprocess_batch(
        imgs_fused, normalize_method=image_normalize_method)
    for j in range(imgs_fused.shape[0]):
        img_np = imgs_fused[j].numpy().transpose(1, 2, 0) # 64x64x3
        # img_path = os.path.join(result_sub_dir, 'fused_%d.png' % j) # 이미지 저장할 파일
        # imwrite(img_path, img_np) # 이미지 저장

    return img_np.tobytes()

if __name__ == '__main__':
    main()
